---
title: "Elsa-analysis1"
output: html_document
date: "2023-09-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, warning=FALSE, echo=FALSE}
## Load required libraries
library(ggnewscale) # this package allows you to have multiple fill and color scales when using ggplot2, a common plotting tool in R. 
library(ggtree) # this package creates visual representations of phylogenetic trees
library(R.utils) # this is a utility package, it helps R run smoothly
library(tidyverse) # this is a utility package, it helps R run smoothly
library(ape) # APE stands for 'Analyses of Phylogenetics and Evolution,' thus this package is used for phylogenetic analysis
library(devtools) # this is a utility package, it helps R run smoothly
library(ggplot2) # ggplot2 is a helpful package for making graphs in R. 
library(hillR) # this package is used to calculate Hill numbers, a metric for 'combined' diversity 
library(spaa) # this package holds tools used for the analysis of species associations, and niche overlap
library(vegan) # Vegan is a common package used for the analysis of ecology data. Here, we apply it for its tools on diversity analysis. 
library(hilldiv) # this package is used for the calculation of Hill numbers (see also hillR)

library(Rhdf5lib)
library(phyloseq)

library(phytools) #phytools is a package that focuses on comparative phylogenetic analysis 

library(microbiome) 

library(matrixStats) # this package is used for opperations performed on matrices

library(microbiomeutilities) 

library(lme4) # this package is used for fitting and analyzing linear and nonlinear models/ 
library(MuMIn) # MuMIn = Multi-model inference, and contains function for information-theoretic model selection, and model averaging 
library(nlme) # this package contains packages related to nonlinear mixed-effects models
library(knitr) # Knitr is a package for turning R script into reports, used here for the generation of an R markdown document 
library(kableExtra) # Kable builds on Knitr, and adds extra functions
library(pairwiseAdonis) # this is a function of (vegan) and is used for multi-level pairwise comparison
library(sjPlot) # this package is used for visualizing statistical analysis 

# library(distillR) #ERROR package ‘DistillR’ is not available for this version of R

library(RColorBrewer) # this is a series of preset color palettes
library(reshape2) # this package is used for reformatting and "reshaping" data to fit ideal formats 
library(ggpubr) # this package is used for formatting ggplot2 figures to be publication ready. 
library(ggdendro) # this package allows you to apply ggplot2 to make Dendrograms and tree diagrams. 
library(grid) # this package adds gridlines to existing plots
library(gplots)
library(dendextend) # this package allows you to extend dendrograms made in R, for the purposes of visualization and comparison. 
library(stringr) # this is a utility package
library(Rtsne) # this is a utility package 
library(glue) # this is a utility package
library(webshot2)
```


```{r directories, comment="", echo=FALSE, message=FALSE, warning=FALSE}

## Download the tables from, change the working directory and files names if needed

## in this section you define the names and locations of the files you will be using, and the working directory you will be using for the rest of the script.

## Declare directories and files
workingdir="/Users/elsa/Desktop/THESIS/Thesis"
counts_file="/Users/elsa/Desktop/THESIS/Thesis/DMB0024_counts.tsv"
tree_file="/Users/elsa/Desktop/THESIS/Thesis/DMB0024.tree"
taxonomy_file="/Users/elsa/Desktop/THESIS/Thesis/DMB0024_mag_info.tsv"
metadata_file="/Users/elsa/Desktop/THESIS/Thesis/DMB0024_metadata.tsv"
coverage_file="/Users/elsa/Desktop/THESIS/R-analysis1/DMB0024_coverage.tsv"
```

```{r loaddata, comment="", echo=FALSE, message=FALSE, warning=FALSE}
## Load data 
setwd(workingdir) # this line sets the working directory of the script to the location established in the block above, where i defined 'workingdir'

# the lines below take the tables imported above, and turn them into readable table files we can use for the rest of our analysis.  
counts_table <- read.table(counts_file, sep="\t",row.names=1,header=T)
coverage_table <- read.table(coverage_file, sep="\t",row.names=1,header=T)
metadata <- read.table(metadata_file,sep="\t",header=T)%>%
	rename(sample=EHI_plaintext)
mags_table <- read.table(taxonomy_file,sep="\t",header=T)
tree <- read.tree(tree_file)

# ELSA NOTE:  here I changed the lines a bit because my files did not need to be unzipped. 

# Load EHI taxonomy colours. Download it first if you have not them in your computer
#colours_URL="https://raw.githubusercontent.com/earthhologenome/EHI_taxonomy_colour/main/ehi_phylum_colors.tsv"
#download.file(colours_URL, "ehi_phylum_colors.tsv")

# in this section we upload the EHI's standard color palatte. This is so that all EHI analyses follow a similar format, for ease of readability and comprehension. 

ehi_phylum_colors <- read.table("~/Desktop/Thesis/R-analysis1/ehi_phylum_colors.tsv",sep="\t",header=T,comment.char = "")

#Delete *__ from the taxonomy names
ehi_phylum_colors1 <- ehi_phylum_colors %>%
  mutate_at(vars(phylum), ~ str_replace(., "[dpcofgs]__", ""))
taxonomyclean <- mags_table%>%
  mutate_at(vars(domain,phylum,class,order,family,genus,species), ~ str_replace(., "[dpcofgs]__", ""))
```

```{r summary, echo=FALSE, message=FALSE, warning=FALSE}
nsamples <- ncol(counts_table) # this line defines our number of samples, by reading from the counts table
metagenomic_bases <- sum(metadata$metagenomic_bases) #this line defines the number of metagenomic bases, by summing each sample from the metadata file. 
host_bases <- sum(metadata$host_bases) #this line defines the number of host bases, from the sum from each sample from the metadata file
discarded_bases <- sum(round(((metadata$metagenomic_bases+metadata$host_bases)/(1-metadata$bases_lost_fastp_percent))-(metadata$metagenomic_bases+metadata$host_bases))) # this line defines the number of discarded bases 
total_bases <- discarded_bases + host_bases + metagenomic_bases # this line defines the number of total bases
singlem_bases <- sum(metadata$metagenomic_bases * metadata$singlem_fraction) 
nmags <- nrow(counts_table) # this line defines the number of MAGs
new_species <- mags_table %>%
	filter(species == "s__") %>%
	nrow()

sequencing_depth <- colSums(counts_table) # this line defines a variable for sequencing depth
sequencing_depth_sum <- sum(sequencing_depth) # this line defines a variable for total sequencing depth sum 
sequencing_depth_mean <- mean(sequencing_depth) # this line defines the variable for mean sequencing depth
sequencing_depth_sd <- sd(sequencing_depth) # this line defines a variable for the standard deviation for the mean sequencing depth. 
```

# 1. Data pre-processing

## 1.1 General statistics

**Number of samples in total**
```{r nsamples, comment="", echo=FALSE, message=FALSE, warning=FALSE}
cat(nsamples) # this tells you the number of samples included in analysis = 58

# cat() is used to concatenate strings. Thus, cat(nsamples) will tell us the number of samples in a readable integer form
```

**Number of MAGs**
The number of metagenome-assembled genomes (MAG) or draft bacterial genomes reconstructed from the metagenomic data.

```{r nmags, comment="", echo=FALSE, message=FALSE, warning=FALSE}
cat(nmags) # this tells you the number of metagenome-assembled genomes (MAGs) included in analysis = 472
```

**Amount of total data (GB):**
The amount of total DNA data sequenced in gigabases (GB, one billion nucleotide bases).

```{r totalGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
totalgb <- round(total_bases / 1000000000,2) #this line defines a variable, 'totalgb,' to be the total number of bases, written in the unit Gigabases. The ',2' denotes that the output is round to 2 decimal points. 

cat(totalgb) # total DNA sequenced = 333.71 gigabases
```

**Amount of discarded data (GB):**
The amount of data discarded due to low quality or lack of informativeness during data preprocesing. Discarding 5-15% of the produced data is within the expected range, due to formation of adaptor dimers, inclusion of adaptors in sequencing reads due to short insert sizes, low sequencing quality, etc.

```{r discardedGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
discardgb <- round(discarded_bases / 1000000000,2)
cat(discardgb) # total amount of discarded data (low quality, lack of info) = 10.37 Gigabases
```

**Amount of discarded data (in % of the raw data):**

```{r %discarded, comment="", echo=FALSE, message=FALSE, warning=FALSE}
discarddata <- round(discarded_bases / total_bases * 100,2) #similar to the above calculations that convert to Gigabases, this line converts to a percentage value. 
cat(discarddata) # amount of discarded data = 3.11% of total data. 3.11<5%, therefore good! and within expected range. 
```

**Amount of host data (GB):**
The amount of data mapped against the host genome. The percentage refers to the amount of data mapped to the host genome respect to quality-filtered data. Note that this value can be very variable depending on the biological features of the sample (e.g., anal swabs contain more host DNA than faeces) and the employed reference genome (e.g., the chances for mapping to the genome are lower as the distance between) the study species and the employed reference genome differ).

```{r hostGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
hostGB <- round(host_bases / 1000000000,2)
cat(hostGB) # amount of host data = 6.49 gigabases
```

**Amount of host data (% of the quality-filtered data):**

```{r host%, comment="", echo=FALSE, message=FALSE, warning=FALSE}
hostdata <- round(host_bases / (total_bases-discarded_bases) * 100,2)
cat(hostdata) # host data represents 2.01% of quality filtered data
```

**Estimated prokaryotic data:** 
The amount and proportion of data belonging to prokayotic genomes respect to the total metagenomic fraction, as estimated from singleM analysis. Note that this is an estimation that relies on the genome sizes of genomes available in reference databases. If a given taxon is not properly represented, genome size estimations can be less accurate.

```{r prokaGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
prokaGB <- round(singlem_bases / 1000000000,2)
cat(prokaGB) # an estimated amount of prokaryotic data = 293.14 gigabases of data
```

**Estimated prokaryotic data (% of the metagenomic data):** 

```{r proka%, comment="", echo=FALSE, message=FALSE, warning=FALSE}
prokadata <- round(singlem_bases / (metagenomic_bases) * 100,2)
cat(prokadata) # prokaryotic data is estimated to be 92.51% of metagenomic data. 
```

**Amount of metagenomic data (GB):**
The amount of data mapped against the host genome. The percentage refers to the amount of data mapped to the host genome respect to quality-filtered data. Note that this value can be very variable depending on the biological features of the sample (e.g., anal swabs contain more host DNA than faeces) and the employed reference genome (e.g., the chances for mapping to the genome are lower as the distance between) the study species and the employed reference genome differ).

```{r metaGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
metaGB <- round(metagenomic_bases / 1000000000,2)
cat(metaGB) # =316.85 gigabases of metagenomic data
```

**Amount of metagenomic data (% of the quality-filtered data):**

```{r meta%, comment="", echo=FALSE, message=FALSE, warning=FALSE}
metaperce <- round(metagenomic_bases / (total_bases-discarded_bases) * 100,2)
cat(metaperce) # = 97.99%  metagenomic data
```

**Total mapped sequencing depth (million reads):**
The amount of reads (and nucleotide bases) that were mapped to the entire MAG catalogue. Note that the amount of bases is only an approximation estimated by multiplying the exact number of mapped reads by 250 bp.

```{r totalreads, comment="", echo=FALSE, message=FALSE, warning=FALSE}
totalreads <- round(sequencing_depth_sum / 1000000,2)
cat(totalreads) # = 1833.71 million reads
```

**Total mapped sequencing depth (GB):**

```{r mappedGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
mappedGB <- round(sequencing_depth_sum / 1000000000 * 143,2)
cat(mappedGB) # total mapped sequencing depth = 262.22 gigabases
```

**Average mapped sequencing depth (million reads):** 
This is the average number of reads (and nucleotide bases) mapped to each sample. Note that the amount of bases is only an approximation estimated by multiplying the exact number of mapped reads by 250 bp.
```{r meanreads, comment="", echo=FALSE, message=FALSE, warning=FALSE}
meanreads <- round(sequencing_depth_mean / 1000000,2)
cat(meanreads) # average mapped sequencing depth = 31.62 million reads
```

**Average mapped sequencing depth (GB):** 
```{r meanGB, comment="", echo=FALSE, message=FALSE, warning=FALSE}
meanGB <- round(sequencing_depth_mean / 1000000000 * 143,2)
cat(meanGB) # average mapped sequencing depth = 4.52 gigabases 
```

## 1.2 MAG catalogue

### 1.2.1 Phylogenetic tree
The phylogenetic tree is constructed by placing the MAG sequences within the reference archaeal and bacterial trees using GTDBTK, followed by merging both trees.

```{r list_phyla, echo=FALSE, warning=FALSE}
phyla <- ehi_phylum_colors1 %>%
  right_join(taxonomyclean, by=join_by(phylum == phylum)) %>% 
	arrange(match(genome, tree$tip.label)) %>% 
  select(phylum, colors) %>%
	unique()

# First, this chunk joins the ehi color palatte   to the genome taxonomy file specific to my data, joining them at the phylum level.
# arrange() reorders the rows of a data frame via the collunm names
# match() then matches genome to the bins 
```

```{r circular_tree_prep, echo=FALSE, warning=FALSE, comments="", message=FALSE, results="hide"}
heatmap <- ehi_phylum_colors1 %>%
  right_join(taxonomyclean, by=join_by(phylum == phylum)) %>%
	arrange(match(genome, tree$tip.label)) %>%
  select(genome,phylum) %>%
	mutate(phylum = factor(phylum, levels = unique(phylum))) %>%
	column_to_rownames(var = "genome")

colors_alphabetic <- ehi_phylum_colors1 %>%
  right_join(taxonomyclean, by=join_by(phylum == phylum)) %>%
	arrange(match(genome, tree$tip.label)) %>%
  select(phylum, colors) %>%
	unique() %>%
	arrange(phylum) %>%
	select(colors) %>%
	pull()

circular_tree <- force.ultrametric(tree,method="extend") %>%
	ggtree(., layout = 'circular', size = 0.3)

circular_tree <- gheatmap(circular_tree, heatmap, offset=0.65, width=0.1, colnames=FALSE) +
		scale_fill_manual(values=colors_alphabetic) +
		geom_tiplab2(size=1, hjust=-0.1) +
		theme(plot.margin = margin(0, 0, 0, 0), panel.margin = margin(0, 0, 0, 0))

print(circular_tree)
```

### 1.2.2 MAG details
Overview of the taxonomy and genome characteristics of the MAGs.\
**Completeness:** completeness of the MAG according to CheckM assessment.\
**Contamination:** contamination or redundancy of the MAG according to CheckM assessment.\
**Size:** size of the MAG in megabases (MB, one million nucleotide bases).

```{r complet_conta, comment="", echo=FALSE, message=FALSE, warning=FALSE}
comp_cont <- taxonomyclean %>%
  select(c(genome,phylum,completeness,contamination,mag_size)) %>%
  mutate(mag_size=round(mag_size/1000000,2)) %>% #change mag_size to MBs
  rename(comp=completeness,cont=contamination,size=mag_size) %>% 
  remove_rownames() %>%
  arrange(match(genome, rev(tree$tip.label))) #sort MAGs according to phylogenetic tree
```
```{r complet_conta_table, comment="", echo=FALSE, message=FALSE, warning=FALSE}
comp_cont_table <- comp_cont %>% 
  select(-genome) %>% 
  group_by(phylum) %>% 
  summarise_at(.vars = names(.)[c(2,3,4)],.funs = c(mean="mean", sd="sd"))
comp_cont_table <- comp_cont_table[,c(1,2,5,3,6,4,7)]
knitr::kable(comp_cont_table, format = "html", full_width = F,col.names = c("Phylum", "Completeness Mean", "Completeness SD", "Contamination Mean", "Contamination SD", "Size Mean", "Size SD"), digits = 2) %>%
  kable_styling(latex_options="scale_down")
```

```{r plot_mag_stats, echo=FALSE, warning=FALSE}
ggscatter(comp_cont, x = "comp", y = "cont", color="phylum", 
          add = "reg.line", conf.int = TRUE,  add.params = list(color = "black", fill = "lightgray"),
          cor.coef = TRUE, cor.method = "kendall", size = "size",
          cor.coeff.args = list(method = "kendall", label.x = 80, label.sep = "\n"), 
          xlab = "Completeness", ylab = "Contamination", legend="right") +
				scale_color_manual(values=colors_alphabetic) +
  guides(col=guide_legend("Phylum"),
         size=guide_legend("MAG size"))
```


ELSA NOTE: this table appears to be clustered differently than the one in the DMB0024 file you sent me (see cluster here in Q4, rather than cluster in Q2 on the PDF). Though if I remember correctly, this figure matches the one you showed me in our meeting Monday morning. 

## 1.3 Sequencing depth assessment
When performing genome-resolved metagenomic analyses on host-associated microbial communities, the data usually contains a mixture of origins.
  One fraction is low-quality data that is discarded in the bioinformatic preprocessing due to lack of informativeness. These data include low-quality bases, adaptors, low-complexity reads and alike, which do not contribute to the study. Another fraction belongs to the host genome against which the data are mapped. The host fraction can be very variable depending on the species and the sample type, and while it is not informative for metagenomic analyses, it can be used for genomic analyses. The rest is what we call the metagenomic fraction. Part of the metagenomic fraction is built into draft bacterial genomes or MAGs, against which metagenomic reads are mapped later on to quantify relative representation of genomes. The fraction that is not built into MAGs is what is also unmapped against the MAG catalogue. This last fraction includes DNA dietary items, viruses and other organisms, but can values_to include prokaryotic DNA of bacteria and archaea that were unable to be reconstructed.

In order to have representative results, the number of reads mapped to the MAG catalogue should be similar across samples. However, multiple reasons can create large imbalances, including uneven sequencing depth, different microbiome complexity across samples, different amount of host or non-microbial reads in the dataset, etc. The following plot shows the distribution of reads across samples.


```{r data_fraction, warning=FALSE, echo=FALSE, fig.height=5}
# Calculate sequence fractions
sequence_fractions <- counts_table %>%
  rownames_to_column("Genome") %>%
  pivot_longer(-Genome, names_to = "sample", values_to = "value") %>%
  group_by(sample) %>%
  summarise(mags = sum(value)) %>%
	left_join(metadata, by = join_by(sample == sample))  %>%
	select(sample,mags,metagenomic_bases,host_bases,bases_lost_fastp_percent) %>%
	mutate(mags_bases = mags*146) %>%
	mutate(lowqual_bases = ((metagenomic_bases+host_bases)/(1-bases_lost_fastp_percent))-(metagenomic_bases+host_bases)) %>%
	mutate(unmapped_bases = metagenomic_bases - mags_bases) %>%
	select(sample,mags_bases,unmapped_bases,host_bases,lowqual_bases)

mags_bases_mean <- sequence_fractions %>%
	mutate(mags_bases = mags_bases / 1000000000) %>%
	select(mags_bases) %>%
	mean()

sequence_fractions_pivot <- sequence_fractions %>%
	pivot_longer(!sample, names_to = "fraction", values_to = "value") %>%
	mutate(value = value / 1000000000) %>%
	mutate(fraction = factor(fraction, levels = c("lowqual_bases","host_bases","unmapped_bases","mags_bases")))

sequence_fractions_meta <- merge(sequence_fractions_pivot, metadata, by="sample")

```

```{r data_fraction_barplot, echo=FALSE, warning=FALSE}
ggplot(sequence_fractions_meta, aes(x = sample, y = value, fill=fraction)) +
  geom_bar(position="stack", stat = "identity") +
  scale_fill_manual(name=NULL,
                    breaks=c("lowqual_bases","host_bases","unmapped_bases","mags_bases"),
                    labels=c("Low quality","Host","Unmapped", "MAGs"),
                    values=c("#CCCCCC","#178a94","#ee8080","#d03161")) +
#  geom_hline(yintercept = mags_bases_mean, linetype = "dashed", color = "black") +
  facet_grid(~region, scale="free", space="free") + # grouped the samples by region
  labs(x = "Samples", y = "Amount of data (GB)") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 6),
        strip.text.x = element_text(size = 7, face = "bold"),
        strip.background = element_rect(colour=NA, fill=NA),
        panel.background = element_rect(fill = NA, color = "black"),
        panel.border = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
        legend.position="bottom",
        legend.title=element_blank())

```

## 1.4 Minimum genome-coverage filtering
Mapping of sequencing reads against the reference genome catalogue is not perfect, and in consequence, all MAGs tend to get a few reads assigned. Implementing a minimum genome coverage filter aims at minimising artificial inflation of diversity due to this artifact of genome-resolved metagenomic analysis. However, if the sequencing depth is low and uneven across samples, this filtering can also introduce more distorsion.

```{r coverage, echo=FALSE, warning=FALSE}
#Apply coverage filtering filtering
min_coverage=0.3
count_table_cov <- coverage_table %>%
  mutate(across(everything(), ~ ifelse(. > min_coverage, 1, 0))) %>%
  map2_df(., counts_table, ~ .x * .y) %>%
  as.data.frame()
rownames(count_table_cov) <- rownames(coverage_table)
```

## 1.5 Genome-size normalisation
Bacterial genomes can vary between 1 and 8 MB, which make relative representation of each genome dependent on its size. To account for genome size biases, read-counts can be normalised by applying a normalisation factor that modifies the read numbers according to the size of each genome compared to the average genome size in the dataset.

```{r genome_norm, echo=FALSE, warning=FALSE}
#Transform by mean MAG-size
mags_table1 <- column_to_rownames(mags_table, "genome")
genome_read_sizes <- mags_table1[rownames(count_table_cov),] %>%
    select(mag_size) %>%
    mutate(mag_size = mag_size / 143) %>% #143 nt is the average read-length after quality filtering in EHI data
    pull()
count_table_cov_size <- sweep(count_table_cov, 1, genome_read_sizes, "/")

count_table_cov_size_rel <- count_table_cov_size %>%
  rownames_to_column("Genome") %>%
  mutate_at(vars(-Genome),~./sum(.)) #TSS normalisation
```
## 1.6 Count table
Once low-coverage genome counts have been filtered out, and the read counts have been normalised into genome counts, we can visualise the relative MAG abundances per sample. Note that the count scale is log-transformed.

```{r cov_size_heatmap, echo=FALSE, warning=FALSE, comments="", message=FALSE, results="hide"}
vertical_tree <- force.ultrametric(tree,method="extend") %>%
		ggtree(., size = 0.3)

#Add phylum colors
vertical_tree <- gheatmap(vertical_tree, heatmap, offset=0, width=0.1, colnames=FALSE) +
	scale_fill_manual(values=colors_alphabetic)

#Reset fill scale
vertical_tree <- vertical_tree + new_scale_fill()

#Add counts
vertical_tree <- gheatmap(vertical_tree, log10(count_table_cov_size), offset=0.04, width=3.5, colnames=TRUE, colnames_angle=90, font.size=2, colnames_position="top", colnames_offset_y = 9) +
	vexpand(.08) +
	coord_cartesian(clip = "off") +
	scale_fill_gradient(low = "white", high = "steelblue", na.value="white")
```
```{r plot_tree, echo=FALSE, warning=FALSE, comments="", message=FALSE}
#Plot tree
vertical_tree +
	theme(legend.position='bottom',legend.key.size = unit(0.3, 'cm')) + labs(fill='Counts')
```


This appears to match the figure in the PDF report, though I am working now to correct the legand. 

# 2. Taxonomic composition
Note that TSS normalisation simply divides each count value for the total count for the sample, thus transforming the data to 0-1 scale.

```{r taxo_comp, echo=FALSE, warning=FALSE}
count_table_cov_size_pivot <- count_table_cov_size %>%
  rownames_to_column("Genome") %>%
  mutate_at(vars(-Genome),~./sum(.)) %>% #apply TSS nornalisation
  pivot_longer(-Genome, names_to = "sample", values_to = "count") %>% #reduce to minimum number of columns
  left_join(., mags_table, by = join_by(Genome == genome)) %>% #append taxonomy
  mutate(phylum = fct_relevel(phylum, rev(ehi_phylum_colors$phylum))) #sort phyla by taxonomy

count_table_cov_size_pivot <- count_table_cov_size_pivot %>%
  mutate_at(vars(domain,phylum,class,order,family,genus,species), ~ str_replace(., "[dpcofgs]__", "")) #delete __ from the taxonomy

count_table_cov_size_pivot_meta <- metadata[c(1,4)] %>%
    merge(., count_table_cov_size_pivot, by="sample") #merge the metadata, 4 indicates region, 1 indicates sample

# Retrieve taxonomy colors to use standardised EHI colors

phylum_colors <- ehi_phylum_colors1 %>%
  filter(phylum %in% unique(count_table_cov_size_pivot$phylum)) %>%
  select(colors) %>%
  pull() %>%
  rev()
phylum_colors <- c(phylum_colors,"#cccccc") #REMOVE! ONLY FOR ARCHAEANS
# ELSA NOTE: am i meant to remove this line too? ^
```

```{r plot_another, comment="", echo=FALSE, message=FALSE, warning=FALSE}
# Plot stacked barplot
ggplot(count_table_cov_size_pivot_meta, aes(x=sample,y=count,fill=phylum, group=phylum))+ #grouping enables keeping the same sorting of taxonomic units
    geom_bar(stat="identity")+ 
    scale_fill_manual(values=phylum_colors) +
    facet_grid(~region, scale="free", space="free") + # grouped the samples by region
    labs(x = "Samples", y = "Relative abundance") +
    guides(fill = guide_legend(ncol = 4)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 6),
        strip.text.x = element_text(size = 6, face = "bold"),
        strip.background = element_rect(colour=NA, fill=NA),
        panel.background = element_rect(fill = NA, color = "black"),
        panel.border = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
        legend.position="bottom",
        legend.title=element_blank(),
        legend.text = element_text(size=6),
        legend.key.size = unit(0.3, 'cm'))
```


```{r phyloseq, comment="", echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

## Making phyloseq object
# Coerce it into a phylseq
MAGotu <- otu_table(count_table_cov_size, taxa_are_rows = T)
## Coerce taxonomy into a phyloseq OTU table
# Remove first column
taxonomyclean1 <- taxonomyclean[,-1]
# Get the necessary columns, convert to matrix
taxmatrix <- as.matrix(taxonomyclean1[1:8])
# Set MAG name as row names of the dataframe
rownames(taxmatrix) <- taxonomyclean$genome
taxtable <- tax_table(taxmatrix) 

# Set the first column as row names
metadata <- na.omit(metadata)
rownames(metadata) <- NULL
metadata.pre <- column_to_rownames(metadata, "sample")

sample_tab <- sample_data(metadata.pre)

## Coerce tree into a phylseq
tree <- phytools::force.ultrametric(tree, method = "extend")
treephylo = phyloseq::phy_tree(tree)

## Merge into a phyloseq object
physeq <- phyloseq(MAGotu, treephylo, sample_tab,taxtable)

# Plot the phylogenetic tree
# tree_plot <- ggtree(treephylo)

# Print the tree plot
# print(tree_plot)
```

### Phylum percentages

```{r phylum1, comment="", echo=FALSE}

physeq_phylum <- microbiome::aggregate_taxa(physeq, 'phylum')
physeq_phylum_rel <-  microbiome::transform(physeq_phylum, "compositional")
table.rel1 <- physeq_phylum_rel@otu_table*100
means.table.rel1 <- as.data.frame(rowMeans(table.rel1))
sd.table.rel1 <- as.data.frame(rowSds(table.rel1, useNames = TRUE))
summary.phylum1 <- merge(means.table.rel1, sd.table.rel1, by="row.names")
colnames(summary.phylum1) <- c("Phylum","Mean", "SD")
print(summary.phylum1[order(-summary.phylum1$Mean),], row.names = FALSE)

```

# 3. Alpha diversity calculations

Diversity estimations for each sample.\
**Richness:** Number of MAGs per sample (after applying coverage filter).\
**Neutral diversity:** Hill number of q=1 (Shannon diversity), a diversity metric that accounts for richness and eveness (relative abundances) of the MAGs.\
**Phylogenetic diversity:** Phylogenetic Hill number of q=1, a diversity metric that accounts for richness and eveness (relative abundances), as well as phylogenetic relationships among MAGs.\
**Functional diversity:** Functional Hill number of q=1, a diversity metric that accounts for richness and eveness (relative abundances), as well as functional dissimilarities among MAGs.\

```{r nofilter_samples, comment="", echo=FALSE, message=FALSE, warning=FALSE}
count_filtered <- column_to_rownames(count_table_cov_size_rel, "Genome")
#metadata_filtered <- metadata[metadata$Sample %in% rownames(count_filtered)]
```

### Neutral
```{r alpha_div_neutral, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div_neutral <- count_filtered %>%
    t() %>%
    hill_taxa(., q = 1) #calculate neutral alpha diversities
```

#### Average neutral alpha diversities (q1)
```{r div_mean, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div_N <-  as.data.frame(alpha_div_neutral) %>%
  tibble::rownames_to_column("sample") %>%
  merge(., metadata, by="sample")

table_mean_alpha <- alpha_div_N %>% 
  group_by(region) %>% 
  summarise_at(.vars = names(.)[2],.funs = c(mean="mean", sd="sd"))
knitr::kable(table_mean_alpha, format = "html", full_width = F,col.names = c('Groups', 'Mean', 'SD'), digits = 3) %>%
  kable_styling(latex_options="scale_down")
```

```{r alpha_table, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div <- alpha_div_neutral %>%
  as.data.frame() %>%
  rename( "Diversity" = ".")  %>%
  rownames_to_column("sample") %>%
  left_join(sequence_fractions, by = join_by(sample == sample)) %>% #add sequencing depth information
  mutate(depth=round(mags_bases/1000000,3))
```

#### Correlations

```{r correlation2_plot2, comment="", echo=FALSE, message=FALSE, warning=FALSE}
ggscatter(alpha_div, x = "mags_bases", y = "unmapped_bases", color="depth", 
          add = "reg.line", conf.int = TRUE,  add.params = list(color = "gray", fill = "lightgray"),
          cor.coef = TRUE, cor.method = "kendall", size = "Diversity",
          cor.coeff.args = list(method = "kendall", label.x = 3e+9, label.sep = "\n"), 
          xlab = "MAG bases", ylab = "Unmapped reads", legend="right") +
  guides(col=guide_legend("Depth"),
         size=guide_legend("Alpha diversity")) +
  font("legend.title", face = "bold")
```

#### Alpha diversity plots

```{r alpha_div_neutral_plot1, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div_neutral %>%
  enframe() %>% #convert vector to tibble
  rename(sample=1,div=2) %>% #rename columns
  inner_join(., metadata, by="sample") %>% #merge with metadata
  ggplot(aes(x=region,y=div,group=region,color=region))+
    geom_boxplot(alpha=0.2,outlier.shape = NA, width = 0.3, show.legend=FALSE, coef=0)+
    geom_jitter(width = 0.1, show.legend=TRUE)+# shape=21, color="black"
    theme(panel.background = element_blank(),
          panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line = element_line(size = 0.5, linetype = "solid", colour = "black")
          )+
  xlab("Region") + 
  ylab("Alpha diversity")
```


### Phylogenetic
```{r alpha_div_phylo, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div_phylo <- count_filtered %>%
#    column_to_rownames("Genome") %>%
    t() %>% #transpose
    hill_phylo(., tree,q = 1) #calculate neutral phylogenetic diversities
```

#### Average phylogenetic alpha diversities

```{r div_P_mean, comment="", echo=FALSE}
alpha_div_P <-  as.data.frame(alpha_div_phylo) %>%
  tibble::rownames_to_column("sample") %>%
  merge(., metadata, by="sample")

table_mean_alpha_phylo <- alpha_div_P %>%
  group_by(region) %>% 
  summarise_at(.vars = names(.)[2],.funs = c(mean="mean", sd="sd"))

#table_mean_alpha_phylo$Type <- c("Aggressive 2015", "Aggressive 2017","Tame 2015","Tame 2017")

knitr::kable(table_mean_alpha_phylo, format = "html", full_width = F,col.names = c('Groups', 'Mean', 'SD'), digits = 3) %>%
  kable_styling(latex_options="scale_down")

```

#### Alpha diversity plots

```{r alpha_div_phylo_plot1, comment="", echo=FALSE, message=FALSE, warning=FALSE}
alpha_div_phylo %>%
  enframe() %>% #convert vector to tibble
  rename(sample=1,div=2) %>% #rename columns
  inner_join(., metadata, by="sample") %>% #merge with metadata
  ggplot(aes(x=region,y=div,group=region,color=region))+
    geom_boxplot(alpha=0.2,outlier.shape = NA, width = 0.3, show.legend=FALSE, coef=0)+
    geom_jitter(width = 0.1, show.legend=TRUE)+# shape=21, color="black"
    theme(panel.background = element_blank(),
          panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line = element_line(size = 0.5, linetype = "solid", colour = "black")
          )+
  xlab("Region") + 
  ylab("Phylogenetic diversity")
```

## Beta diversity calculations

```{r beta_div_metadata, comment="", echo=FALSE, message=FALSE, warning=FALSE}
metadata_unified <- read.csv("/Users/elsa/Desktop/THESIS/Thesis/metadata_unified.csv")

metadata_unified_clean <- metadata_unified %>%
  filter(sample != "")  # Filter rows where "sample" is not an empty string

selected_columns <- metadata_unified_clean %>%
  select(sample, Pack, PR_results_short, toxocaris_leonina, sarcocystis_spp, Tania_serialis, cryptosporidium, giardia, toxoplasma_gondii, trichincella_spp, Huldscore)

# Merge the selected columns with "metadata" based on the "sample" column
all_metadata <- left_join(metadata, selected_columns, by = "sample")
```


### Neutral
```{r beta_div_neutral, comment="", echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
beta_div_neutral <- count_filtered %>%
#    select(-1) %>% 
    t() %>% #transpose
    hill_taxa_parti_pairwise(., q = 1, pairs = "full") #calculate neutral beta diversities
```

```{r beta_div_neutral_dist, comment="", echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
#### Calculate the distances
beta_div_neutral_dist <- beta_div_neutral %>%
  select(site1,site2,TD_beta) %>%
  as.data.frame()  %>% 
  list2dist()
```

```{r beta_div_neutral_nmds_Status, comment="", echo=FALSE, results='hide'}
#### NMDS
beta_div_neutral_nmds <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., metadata, by="sample")
```

```{r beta_div_neutral_centroids_region,comment="", echo=FALSE}
#### Create centroids
NMDS.centroids_1=aggregate(beta_div_neutral_nmds[,c(2:3)],by=list(beta_div_neutral_nmds$region),FUN=mean)
colnames(NMDS.centroids_1) <- c("region","NMDS1","NMDS2")
beta_div_neutral_nmds=merge(beta_div_neutral_nmds,NMDS.centroids_1,by="region")
```

#### NMDS:
```{r beta_div_neutral_plot_region,comment="", echo=FALSE}
#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds  %>%
  group_by(region)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds, aes(x=NMDS1.x,y=NMDS2.x,colour=region)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```

Adonis
```{r Adonis_Region, comment="", echo=TRUE, message=FALSE, warning=FALSE}

ps.disper.neutral <- betadisper(beta_div_neutral_dist, metadata$region) 
permutest(ps.disper.neutral, pairwise = TRUE) 
# a p value of >0.05 in this case will tell you that the data is in an ok format for running an adonis
## results: P = 0.537

meta_order <- metadata[order(metadata$sample),] 
m1 <- as.matrix(beta_div_neutral_dist) 
metadata_ord<- metadata[order(match(metadata$sample,rownames(m1))),] 
# this section correctly orders the metadata so that it matches to the beta diversity distance matrix

# Run test
adonis2(beta_div_neutral_dist ~ region, data =metadata_ord, permutations = 999)
# this is essentially a MANOVA. a p value of <0.05 is significant. The R2 value will tell you what amount of variation is based off the clustering variable. in this case the region. 

## results: P = 0.001. R2 = 0.12257

## thus, the results ARE statistically significant, and 12% of variation is based on the region

```

Looking at the 6 different sled teams in Daneborg:
```{r Daneborg_packs_nmds, comment="", echo=TRUE, message=FALSE, warning=FALSE}
# Filter the data for Daneborg
filtered_data <- all_metadata %>%
  filter(region == "Daneborg")

# NMDS analysis for Packs in Daneborg
beta_div_neutral_nmds_pack <- beta_div_neutral_dist %>%
  metaMDS(., trymax = 200, k = 2, verbosity = FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., filtered_data, by = "sample")

# Create centroids
NMDS.centroids_2 <- aggregate(beta_div_neutral_nmds_pack[, c(2:3)], by = list(Pack = beta_div_neutral_nmds_pack$Pack), FUN = mean)
colnames(NMDS.centroids_2) <- c("Pack", "NMDS1", "NMDS2")
beta_div_neutral_nmds_pack <- merge(beta_div_neutral_nmds_pack, NMDS.centroids_2, by = "Pack")

# Plot the centroids and the samples
centroids <- beta_div_neutral_nmds_pack %>%
  group_by(Pack) %>%
  summarize(NM1 = mean(NMDS1.y), NM2 = mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_pack, aes(x = NMDS1.x, y = NMDS2.x, colour = Pack)) +
  geom_point(aes(x = NMDS1.x, y = NMDS2.x), size = 2) +
  geom_segment(aes(x = NMDS1.y, y = NMDS2.y, xend = NMDS1.x, yend = NMDS2.x)) +
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title = element_blank(),
        legend.text = element_text(size = 14)) +
  theme_classic() +
  labs(x = "NMDS1", y = "NMDS2")

```

Adonis for the Pack analysis in Daneborg:
```{r Daneborg_packs_adonis, comment="", echo=TRUE, message=FALSE, warning=FALSE}
ps.disper.neutral <- betadisper(beta_div_neutral_dist, all_metadata$Pack) 
permutest(ps.disper.neutral, pairwise = TRUE) 
# a p value of >0.05 in this case will tell you that the data is in an ok format for running an adonis
## results: P = 0.001, therefore NOT appropriate for adonis
################### ALL BELOW NOT RELEVENT #############################


# meta_order_2 <- all_metadata[order(all_metadata$sample),] 
# m2 <- as.matrix(beta_div_neutral_dist) 
# metadata_ord_2<- all_metadata[order(match(all_metadata$sample,rownames(m2))),] 
# this section correctly orders the metadata so that it matches to the beta diversity distance matrix

# Run test
# adonis2(beta_div_neutral_dist ~ Pack, data =metadata_ord_2, permutations = 999)
# this is essentially a MANOVA. a p value of <0.05 is significant. The R2 value will tell you what amount of variation is based off the clustering variable. in this case the packs. 
```

#################################

Now Analysis for presence / absence of parasites: 

```{r Parasites_nmds, comment="", echo=TRUE, message=FALSE, warning=FALSE}
#### NMDS
beta_div_neutral_nmds_PR <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_PR <- beta_div_neutral_nmds_PR %>%
  filter(PR_results_short != "excluded")

#### Create centroids
NMDS.centroids_3=aggregate(beta_div_neutral_nmds_PR[,c(2:3)],by=list(beta_div_neutral_nmds_PR$PR_results_short),FUN=mean)
colnames(NMDS.centroids_3) <- c("PR_results_short","NMDS1","NMDS2")
beta_div_neutral_nmds_PR=merge(beta_div_neutral_nmds_PR,NMDS.centroids_3,by="PR_results_short")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_PR  %>%
  group_by(PR_results_short)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_PR, aes(x=NMDS1.x,y=NMDS2.x,colour=PR_results_short)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")

```
```{r Parasites_adonis, comment="", echo=TRUE, message=FALSE, warning=FALSE}
ps.disper.neutral <- betadisper(beta_div_neutral_dist, all_metadata$PR_results_short) 
permutest(ps.disper.neutral, pairwise = TRUE) 
# a p value of >0.05 in this case will tell you that the data is in an ok format for running an adonis
## results: P = 0.04, therefore NOT appropriate for adonis
################### ALL BELOW NOT RELEVENT #############################


# meta_order_3 <- all_metadata[order(all_metadata$sample),] 
# m3 <- as.matrix(beta_div_neutral_dist) 
# metadata_ord_3<- all_metadata[order(match(all_metadata$sample,rownames(m3))),] 
# this section correctly orders the metadata so that it matches to the beta diversity distance matrix

# Run test
# adonis2(beta_div_neutral_dist_PR ~ PR_results_short, data =metadata_ord_3, permutations = 999)
# this is essentially a MANOVA. a p value of <0.05 is significant. The R2 value will tell you what amount of variation is based off the clustering variable. in this case the parasitic infection.  
```

Now, just for fun, we look at the Ittoq dogs, by their packs: 

```{r Ittoq_packs_nmds, comment="", echo=TRUE, message=FALSE, warning=FALSE}
# Filter the data for Ittoqqortoormiit
filtered_data_2 <- all_metadata %>%
  filter(region == "Ittoqqortoormii")

# NMDS analysis for Packs in Daneborg
beta_div_neutral_nmds_ittoq <- beta_div_neutral_dist %>%
  metaMDS(., trymax = 200, k = 2, verbosity = FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., filtered_data_2, by = "sample")

# Create centroids
NMDS.centroids_4 <- aggregate(beta_div_neutral_nmds_ittoq[, c(2:3)], by = list(Pack = beta_div_neutral_nmds_ittoq$Pack), FUN = mean)
colnames(NMDS.centroids_4) <- c("Pack", "NMDS1", "NMDS2")
beta_div_neutral_nmds_ittoq <- merge(beta_div_neutral_nmds_ittoq, NMDS.centroids_4, by = "Pack")

# Plot the centroids and the samples
centroids <- beta_div_neutral_nmds_ittoq %>%
  group_by(Pack) %>%
  summarize(NM1 = mean(NMDS1.y), NM2 = mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_ittoq, aes(x = NMDS1.x, y = NMDS2.x, colour = Pack)) +
  geom_point(aes(x = NMDS1.x, y = NMDS2.x), size = 2) +
  geom_segment(aes(x = NMDS1.y, y = NMDS2.y, xend = NMDS1.x, yend = NMDS2.x)) +
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title = element_blank(),
        legend.text = element_text(size = 14)) +
  theme_classic() +
  labs(x = "NMDS1", y = "NMDS2")
```
Adonis for Ittoqqortoormiit packs
```{r Ittoq_packs_adonis, comment="", echo=TRUE, message=FALSE, warning=FALSE}
ps.disper.neutral <- betadisper(beta_div_neutral_dist, all_metadata$Pack) 
permutest(ps.disper.neutral, pairwise = TRUE) 
# a p value of >0.05 in this case will tell you that the data is in an ok format for running an adonis
## results: P = 0.001, therefore NOT appropriate for adonis
################### ALL BELOW NOT RELEVENT #############################


# meta_order_4 <- all_metadata[order(all_metadata$sample),] 
# m4 <- as.matrix(beta_div_neutral_dist) 
# metadata_ord_4<- all_metadata[order(match(all_metadata$sample,rownames(m4))),] 
# this section correctly orders the metadata so that it matches to the beta diversity distance matrix

# Run test
# adonis2(beta_div_neutral_dist_ittoq ~ Pack, data =metadata_ord_4, permutations = 999)
# this is essentially a MANOVA. a p value of <0.05 is significant. The R2 value will tell you what amount of variation is based off the clustering variable. in this case the packs.  
```
#########################################################################################################

Looking for if individual parasites impact results:

T. leonina
```{r Individual_Parasites_nmds, comment="", echo=TRUE, message=FALSE, warning=FALSE}
#### NMDS
beta_div_neutral_nmds_tleo <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_tleo <- beta_div_neutral_nmds_tleo %>%
  filter(toxocaris_leonina != "excluded")

#### Create centroids
NMDS.centroids_5=aggregate(beta_div_neutral_nmds_tleo[,c(2:3)],by=list(beta_div_neutral_nmds_tleo$toxocaris_leonina),FUN=mean)
colnames(NMDS.centroids_5) <- c("toxocaris_leonina","NMDS1","NMDS2")
beta_div_neutral_nmds_tleo=merge(beta_div_neutral_nmds_tleo,NMDS.centroids_5,by="toxocaris_leonina")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_tleo  %>%
  group_by(toxocaris_leonina)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_tleo, aes(x=NMDS1.x,y=NMDS2.x,colour=toxocaris_leonina)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")

```

sarcocystis_spp
```{r}
#### NMDS
beta_div_neutral_nmds_sarcocystis <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_sarcocystis <- beta_div_neutral_nmds_sarcocystis %>%
  filter(sarcocystis_spp != "excluded")

#### Create centroids
NMDS.centroids_6=aggregate(beta_div_neutral_nmds_sarcocystis[,c(2:3)],by=list(beta_div_neutral_nmds_sarcocystis$sarcocystis_spp),FUN=mean)
colnames(NMDS.centroids_6) <- c("sarcocystis_spp","NMDS1","NMDS2")
beta_div_neutral_nmds_sarcocystis=merge(beta_div_neutral_nmds_sarcocystis,NMDS.centroids_6,by="sarcocystis_spp")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_sarcocystis  %>%
  group_by(sarcocystis_spp)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_sarcocystis, aes(x=NMDS1.x,y=NMDS2.x,colour=sarcocystis_spp)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```
Tania_serialis
```{r}
#### NMDS
beta_div_neutral_nmds_tser <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_tser <- beta_div_neutral_nmds_tser %>%
  filter(Tania_serialis != "excluded")

#### Create centroids
NMDS.centroids_7=aggregate(beta_div_neutral_nmds_tser[,c(2:3)],by=list(beta_div_neutral_nmds_tser$Tania_serialis),FUN=mean)
colnames(NMDS.centroids_7) <- c("Tania_serialis","NMDS1","NMDS2")
beta_div_neutral_nmds_tser=merge(beta_div_neutral_nmds_tser,NMDS.centroids_7,by="Tania_serialis")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_tser  %>%
  group_by(Tania_serialis)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_tser, aes(x=NMDS1.x,y=NMDS2.x,colour=Tania_serialis)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```
cryptosporidium
```{r}
#### NMDS
beta_div_neutral_nmds_crypto <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_crypto <- beta_div_neutral_nmds_crypto %>%
  filter(cryptosporidium != "excluded")

#### Create centroids
NMDS.centroids_8=aggregate(beta_div_neutral_nmds_crypto[,c(2:3)],by=list(beta_div_neutral_nmds_crypto$cryptosporidium),FUN=mean)
colnames(NMDS.centroids_8) <- c("cryptosporidium","NMDS1","NMDS2")
beta_div_neutral_nmds_crypto=merge(beta_div_neutral_nmds_crypto,NMDS.centroids_8,by="cryptosporidium")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_crypto  %>%
  group_by(cryptosporidium)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_crypto, aes(x=NMDS1.x,y=NMDS2.x,colour=cryptosporidium)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```
giardia
```{r}
#### NMDS
beta_div_neutral_nmds_giardia <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_giardia <- beta_div_neutral_nmds_giardia %>%
  filter(giardia != "excluded")

#### Create centroids
NMDS.centroids_9=aggregate(beta_div_neutral_nmds_giardia[,c(2:3)],by=list(beta_div_neutral_nmds_giardia$giardia),FUN=mean)
colnames(NMDS.centroids_9) <- c("giardia","NMDS1","NMDS2")
beta_div_neutral_nmds_giardia=merge(beta_div_neutral_nmds_giardia,NMDS.centroids_9,by="giardia")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_giardia  %>%
  group_by(giardia)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_giardia, aes(x=NMDS1.x,y=NMDS2.x,colour=giardia)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```
toxoplasma_gondii
```{r}
#### NMDS
beta_div_neutral_nmds_toxoplasma_gondii <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_toxoplasma_gondii <- beta_div_neutral_nmds_toxoplasma_gondii %>%
  filter(toxoplasma_gondii != "excluded")

#### Create centroids
NMDS.centroids_10=aggregate(beta_div_neutral_nmds_toxoplasma_gondii[,c(2:3)],by=list(beta_div_neutral_nmds_toxoplasma_gondii$toxoplasma_gondii),FUN=mean)
colnames(NMDS.centroids_10) <- c("toxoplasma_gondii","NMDS1","NMDS2")
beta_div_neutral_nmds_toxoplasma_gondii=merge(beta_div_neutral_nmds_toxoplasma_gondii,NMDS.centroids_10,by="toxoplasma_gondii")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_toxoplasma_gondii  %>%
  group_by(toxoplasma_gondii)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_toxoplasma_gondii, aes(x=NMDS1.x,y=NMDS2.x,colour=toxoplasma_gondii)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```
trichincella_spp
```{r}
#### NMDS
beta_div_neutral_nmds_trichincella_spp <- beta_div_neutral_dist %>%
  metaMDS(.,trymax = 200, k=2, verbosity=FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., all_metadata, by="sample")

beta_div_neutral_nmds_trichincella_spp <- beta_div_neutral_nmds_trichincella_spp %>%
  filter(trichincella_spp != "excluded")

#### Create centroids
NMDS.centroids_11=aggregate(beta_div_neutral_nmds_trichincella_spp[,c(2:3)],by=list(beta_div_neutral_nmds_trichincella_spp$trichincella_spp),FUN=mean)
colnames(NMDS.centroids_11) <- c("trichincella_spp","NMDS1","NMDS2")
beta_div_neutral_nmds_trichincella_spp=merge(beta_div_neutral_nmds_trichincella_spp,NMDS.centroids_11,by="trichincella_spp")

#### Plot the centroids and the samples. 
centroids <- beta_div_neutral_nmds_trichincella_spp  %>%
  group_by(trichincella_spp)  %>%
  summarize(NM1=mean(NMDS1.y), NM2=mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_trichincella_spp, aes(x=NMDS1.x,y=NMDS2.x,colour=trichincella_spp)) +
  geom_point(aes(x=NMDS1.x,y=NMDS2.x),size=2) + 
  geom_segment(aes(x=NMDS1.y, y=NMDS2.y, xend=NMDS1.x, yend=NMDS2.x))+ 
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title=element_blank(),
        legend.text=element_text(size=14))+
  # facet_wrap(~ factor(type))+
  theme_classic()+
  labs( x = "NMDS1", y = "NMDS2")
```

Huldscore
```{r}
# Filter the data for Ittoqqortoormiit
filtered_data_3 <- all_metadata %>%
  filter(region == "Ittoqqortoormii")

# NMDS analysis for Huldscores in Daneborg
beta_div_neutral_nmds_huldscore <- beta_div_neutral_dist %>%
  metaMDS(., trymax = 200, k = 2, verbosity = FALSE) %>%
  vegan::scores() %>%
  as_tibble(., rownames = "sample") %>%
  inner_join(., filtered_data_3, by = "sample")

# Convert Huldscore to a factor variable
beta_div_neutral_nmds_huldscore$Huldscore <- factor(beta_div_neutral_nmds_huldscore$Huldscore)

# Create centroids
NMDS.centroids_12 <- aggregate(beta_div_neutral_nmds_huldscore[, c(2:3)], by = list(Huldscore = beta_div_neutral_nmds_huldscore$Huldscore), FUN = mean)
colnames(NMDS.centroids_12) <- c("Huldscore", "NMDS1", "NMDS2")
beta_div_neutral_nmds_huldscore <- merge(beta_div_neutral_nmds_huldscore, NMDS.centroids_12, by = "Huldscore")

custom_colors <- c("1" = "red", "2" = "blue", "3" = "green", "4" = "purple")

# Plot the centroids and the samples
centroids <- beta_div_neutral_nmds_huldscore %>%
  group_by(Huldscore) %>%
  summarize(NM1 = mean(NMDS1.y), NM2 = mean(NMDS2.y))

ggplot(beta_div_neutral_nmds_huldscore, aes(x = NMDS1.x, y = NMDS2.x, colour = Huldscore)) +
  geom_point(aes(x = NMDS1.x, y = NMDS2.x), size = 2) +
  geom_segment(aes(x = NMDS1.y, y = NMDS2.y, xend = NMDS1.x, yend = NMDS2.x)) +
  scale_color_manual(values = custom_colors) +  # Set custom colors
  theme(axis.line = element_line(colour = "grey"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title = element_blank(),
        legend.text = element_text(size = 14)) +
  theme_classic() +
  labs(x = "NMDS1", y = "NMDS2")
```


